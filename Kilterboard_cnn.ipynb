{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1D1viyuOIAaiwFEVUMeLxjXrZDfbn57w5",
      "authorship_tag": "ABX9TyOwy7t7gQyOudWF/ae8hOpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atrbyg24/kilter-board/blob/main/Kilterboard_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from string import digits\n",
        "from PIL import Image,ImageOps\n",
        "import time"
      ],
      "metadata": {
        "id": "qn2as7ODeCK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrapeClimbs(angle,minAscents,minGrade,maxGrade):\n",
        "    #angle = multiples of 5 between 0 and 70\n",
        "    #minAscents >=1\n",
        "    #minGrade <= maxGrade 4a/V0 = 10, 4b/V0 = 11,..., 7c/V9 = 26, 7c+/V10 = 27\n",
        "    driver = webdriver.Safari()\n",
        "    driver.maximize_window()\n",
        "    driver.get(f\"https://climbdex.fly.dev/results?name=&angle={angle}&minAscents={minAscents}&minGrade={minGrade}&maxGrade={maxGrade}&sortBy=ascents&sortOrder=desc&minRating=1.0&gradeAccuracy=1&settername=&holds=&mirroredHolds=&board=kilter&layout=1&size=7&set=1&set=20&roleMatch=strict\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    try:\n",
        "        climb_results = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID,\"header-results-count\")))\n",
        "        num_climbs = int(''.join(c for c in climb_results.text if c in digits))\n",
        "        first_climb_button = WebDriverWait(driver,10.).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#div-results-list > button:nth-child(1)\")))\n",
        "        first_climb_button.click()\n",
        "        climb_count = 1\n",
        "\n",
        "        for i in range(num_climbs):\n",
        "            climb_name = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID,\"header-climb-name\")))\n",
        "            climb_stats = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID,\"paragraph-climb-stats\")))\n",
        "            climb_grade = climb_stats.text.split()[0]\n",
        "            climb_fontgrade = climb_grade.split('/')[0]\n",
        "            climb_vgrade = climb_grade.split('/')[1]\n",
        "            try:\n",
        "                driver.find_element(By.ID,\"paragraph-climb-description\")\n",
        "                climb_description = driver.find_element(By.ID,\"paragraph-climb-description\")\n",
        "                outlier = False\n",
        "                if 'none' not in climb_description.get_attribute('class'):\n",
        "                    climb_text = climb_description.text.lower()\n",
        "                    if \"match\" in climb_text or \"campus\" in climb_text:\n",
        "                        outlier = True\n",
        "                if not outlier:\n",
        "                    climb_box = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#svg-climb\")))\n",
        "                    climb_box.screenshot(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                    with Image.open(rf'drive/MyDrive/Data{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png') as im:\n",
        "                        width,height = im.size\n",
        "                        im_cropped = im.crop(((0, 158, width, height)))\n",
        "                        im_cropped.save(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                        im_resized = im_cropped.resize((258, 283), Image.ANTIALIAS)\n",
        "                        im_resized.save(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png',quality=95)\n",
        "                if outlier:\n",
        "                    climb_box = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#svg-climb\")))\n",
        "                    climb_box.screenshot(rf'drive/MyDrive/Data/Outliers/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                    with Image.open(rf'drive/MyDrive/Data/Outliers/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png') as im:\n",
        "                        width,height = im.size\n",
        "                        im_cropped = im.crop(((0, 158, width, height)))\n",
        "                        im_cropped.save(rf'drive/MyDrive/Data/Outliers/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                        im_resized = im_cropped.resize((258, 283), Image.ANTIALIAS)\n",
        "                        im_resized.save(rf'drive/MyDrive/Data/Outliers/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png',quality=95)\n",
        "                climb_count+=1\n",
        "                right_arrow = WebDriverWait(driver,10.).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#button-next\")))\n",
        "                right_arrow.click()\n",
        "                time.sleep(2)\n",
        "\n",
        "            except:\n",
        "                climb_box = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#svg-climb\")))\n",
        "                climb_box.screenshot(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                with Image.open(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png') as im:\n",
        "                    width,height = im.size\n",
        "                    im_cropped = im.crop(((0, 158, width, height)))\n",
        "                    im_cropped.save(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png')\n",
        "                    im_resized = im_cropped.resize((258, 283), Image.ANTIALIAS)\n",
        "                    im_resized.save(rf'drive/MyDrive/Data/{climb_vgrade}/{climb_fontgrade}-{climb_vgrade}-{climb_count}.png',quality=95)\n",
        "                climb_count+=1\n",
        "                right_arrow = WebDriverWait(driver,10.).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#button-next\")))\n",
        "                right_arrow.click()\n",
        "                time.sleep(2)\n",
        "\n",
        "\n",
        "    except:\n",
        "            driver.quit()\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "g8N-iKaLw5WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Get the root directory of the dataset\n",
        "root_dir = 'drive/MyDrive/Data'\n",
        "\n",
        "# Get a list of all subdirectories (folders) in the root directory\n",
        "subdirectories = os.listdir(root_dir)\n",
        "\n",
        "# Create an empty list to store the image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "labels_map = {\n",
        "    \"V1\": 0,\n",
        "    \"V2\": 1,\n",
        "    \"V3\": 2,\n",
        "    \"V4\": 3,\n",
        "    \"V5\": 4,\n",
        "    \"V6\": 5,\n",
        "    \"V7\": 6,\n",
        "    \"V8\": 7,\n",
        "}\n",
        "\n",
        "# Iterate through each subdirectory\n",
        "for subdirectory in subdirectories:\n",
        "    # Get the path of the current subdirectory\n",
        "    subdirectory_path = os.path.join(root_dir, subdirectory)\n",
        "\n",
        "    # Get a list of all files in the current subdirectory\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "      files = os.listdir(subdirectory_path)\n",
        "\n",
        "    # Iterate through each file in the current subdirectory\n",
        "    for file in files:\n",
        "        # Get the path of the current file\n",
        "        file_path = os.path.join(subdirectory_path, file)\n",
        "\n",
        "        # Check if the current file is an image\n",
        "        if file.endswith('.png'):\n",
        "            # Add the image path and label to the lists\n",
        "            image_paths.append(file_path)\n",
        "            labels.append(labels_map[subdirectory])\n",
        "\n",
        "# Create a Pandas DataFrame from the lists\n",
        "df = pd.DataFrame({\n",
        "    'images': image_paths,\n",
        "    'labels': labels\n",
        "})\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('kilterboard.csv', index=False)"
      ],
      "metadata": {
        "id": "WcL55uqsf_ZG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XL7Zf7a9OE4p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.io import read_image\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from skimage import io, transform\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "\n",
        "class KilterboardDataset(Dataset):\n",
        "    #Kilterboard dataset\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.kilterboard_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.kilterboard_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.kilterboard_frame.iloc[idx, 0]\n",
        "        image = read_image(img_path,mode=ImageReadMode.RGB)\n",
        "        image = image.type(torch.FloatTensor)\n",
        "        label = self.kilterboard_frame.iloc[idx, 1]\n",
        "        return image, label\n",
        "\n",
        "class ApplyTransform(Dataset):\n",
        "    \"\"\"\n",
        "    Apply transformations to a Dataset\n",
        "\n",
        "    Arguments:\n",
        "        dataset (Dataset): A Dataset that returns (sample, target)\n",
        "        transform (callable, optional): A function/transform to be applied on the sample\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, target = self.dataset[idx]\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, target\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "])\n"
      ],
      "metadata": {
        "id": "4DkKxSf86dGY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kilterboard_dataset = KilterboardDataset(csv_file='drive/MyDrive/kilterboard.csv',\n",
        "                                    root_dir='drive/MyDrive/Data')\n",
        "generator1 = torch.Generator().manual_seed(17)\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(kilterboard_dataset, [0.8, 0.2],generator = generator1)\n",
        "transformed_train = ApplyTransform(train_dataset,train_transform)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(transformed_train, batch_size=batch_size,shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle = False)\n"
      ],
      "metadata": {
        "id": "4yGkHpUw9RZR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class ConvNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 8, 3)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(8,16,5)\n",
        "      self.conv3 = nn.Conv2d(16,32,5)\n",
        "      self.fc1 = nn.Linear(29696, 1024)\n",
        "      self.fc2 = nn.Linear(1024, 128)\n",
        "      self.fc3 = nn.Linear(128,8)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = self.pool(F.relu(self.conv3(x)))\n",
        "      x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "model = ConvNeuralNet().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "vjKV2SErHwKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e297c6e-7d1e-41e7-9619-74c01827f005"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "ConvNeuralNet(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=29696, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=8, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "train_size = len(train_dataset)\n",
        "train_classes = [label for _, label in train_dataset]\n",
        "freq = Counter(train_classes)\n",
        "weights = []\n",
        "for i in range(8):\n",
        "  weights.append(train_size/freq[i])\n",
        "weights = torch.tensor(weights)\n",
        "print(weights)"
      ],
      "metadata": {
        "id": "6XIcYCwsP0Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [17.7629, 21.5375,  6.5680,  5.7981,  4.9488,  6.6783,  8.5367,  9.6527]\n",
        "weights = torch.tensor(weights)\n",
        "loss_fn = nn.CrossEntropyLoss(weight = weights.to(device))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X,y = X.to(device),y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X,y = X.to(device),y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fc597Th42D1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "K-ulUA742LVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"kilter_model.pth\")\n",
        "print(\"Saved PyTorch Model State to kilter_model.pth\")"
      ],
      "metadata": {
        "id": "AtEseAKgTOeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNeuralNet().to(device)\n",
        "model.load_state_dict(torch.load(\"kilter_model.pth\"))"
      ],
      "metadata": {
        "id": "DPzDHXbrdHvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('V1', 'V2', 'V3', 'V4',\n",
        "           'V5', 'V6', 'V7', 'V8')\n",
        "\n",
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "5wGBgzmsc4y9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}